## 达观文本智能处理挑战



### Links

[比赛链接](http://www.dcjingsai.com/common/cmpt/%E2%80%9C%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%9D%E6%96%87%E6%9C%AC%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%8C%91%E6%88%98%E8%B5%9B_%E7%AB%9E%E8%B5%9B%E4%BF%A1%E6%81%AF.html)



### 比赛介绍

达观数据提供了一批长文本数据和分类信息，希望选手动用自己的智慧，结合当下最先进的NLP和人工智能技术，深入分析文本内在结构和语义信息，构建文本分类模型，实现精准分类。

线下颁奖：2018年9月16日

**建立模型通过长文本数据正文(article)，预测文本对应的类别(class)**   

![](Daguan/幻灯片7.jpg)

数据包含2个csv文件：
》**train_set.csv**：此数据集用于训练模型，每一行对应一篇文章。文章分别在“字”和“词”的级别上做了脱敏处理。共有四列：
第一列是文章的索引(id)，第二列是文章正文在“字”级别上的表示，即字符相隔正文(article)；第三列是在“词”级别上的表示，即词语相隔正文(word_seg)；第四列是这篇文章的标注(class)。
注：每一个数字对应一个“字”，或“词”，或“标点符号”。“字”的编号与“词”的编号是独立的！
》**test_set.csv**：此数据用于测试。数据格式同train_set.csv，但不包含class。
注：test_set与train_test中文章id的编号是独立的。





### Top Solutions

Rank1: <https://github.com/ShawnyXiao/2018-DC-DataGrand-TextIntelProcess>
Rank2：<https://github.com/CortexFoundation/->
Rank4: <https://github.com/hecongqing/2018-daguan-competition>
Rank8：<https://github.com/Rowchen/Text-classifier>
Rank10: <https://github.com/moneyDboat/data_grand> 

Rank11：<https://github.com/TianyuZhuuu/DaGuan_TextClassification_Rank11>
Rank18: <https://github.com/nlpjoe/daguan-classify-2018>
RankX: <https://github.com/yanqiangmiffy/daguan>



### 学习记录

***

#### 2019.3.6



Rank1: https://github.com/ShawnyXiao/2018-DC-DataGrand-TextIntelProcess

只有一个思路PPT没有源码



Rank2：https://github.com/CortexFoundation/-

有详尽源码但没有思路说明，来自Cortex Lab



Rank4: https://github.com/hecongqing/2018-daguan-competition

有详尽源码与.sh但思路不够详尽

Glove用C



Rank8：https://github.com/Rowchen/Text-classifier

有详尽代码，思路详尽有PPT，代码结构明确有.sh，可作为优先学习方案

有值得参考的冗余模型选择部分

Glove有python配置脚本



Rank10: <https://github.com/moneyDboat/data_grand> 

有对应的专栏文章：[“达观杯”文本分类挑战赛Top10经验分享](https://zhuanlan.zhihu.com/p/45391378)

使用pytorch 

- 简洁易用：Pytorch的设计追求最少的封装，尽量避免重复造轮子。
- 动态图实现：代码简洁直观，同时让调试更加简单。
- 易于学习掌握：Pytorch提供了清晰的文档和指南，以及论坛[PyTorch Forums](http://link.zhihu.com/?target=https%3A//discuss.pytorch.org/)，遇到的问题基本上都能在论坛中查到。

一个模型训练完需要超过十个小时

模型融合：概率等权重融合

该作者还写了一篇 [文本关键词提取算法总结和Python实现](https://zhuanlan.zhihu.com/p/49049482)





#### 2019.3.7 - 3.8

Rank11：<https://github.com/TianyuZhuuu/DaGuan_TextClassification_Rank11>

用3个深度不同的LGB模型进行stacking(每个深度10个随机种子，共30个)，所用模型的结果使用HillClimbing集成计算权重， 加权得到预测结果



Rank18: <https://github.com/nlpjoe/daguan-classify-2018>

有详细的EDA来描述数据预处理过程可以学习

整个建模的步骤包括

- [数据预处理](Daguan/数据描述EDA.md)
- [baseline模型训练](Daguan/baseline.md)
- [深度模型训练](Daguan/深度模型训练.md)


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from config import GROUP_DICT, MAX_PAGE, SQL_DICT, HEADERS, PROXY_POOL_URL, MAX_GET_RETRY, OUTPUT_PATH\n",
    "from base import _Sql_Base\n",
    "import requests\n",
    "import emoji\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "\n",
    "class HTTPError(Exception):\n",
    "\n",
    "    \"\"\" HTTP状态码不是200异常 \"\"\"\n",
    "\n",
    "    def __init__(self, status_code, url):\n",
    "        self.status_code = status_code\n",
    "        self.url = url\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s HTTP %s\" % (self.url, self.status_code)\n",
    "    \n",
    "\n",
    "def get_logger(name):\n",
    "    \"\"\"logger\n",
    "    \"\"\"\n",
    "    default_logger = logging.getLogger(name)\n",
    "    default_logger.setLevel(logging.DEBUG)\n",
    "    stream = logging.StreamHandler()\n",
    "    stream.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter(\"[%(levelname)s] %(asctime)s - %(message)s\")\n",
    "    stream.setFormatter(formatter)\n",
    "    default_logger.addHandler(stream)\n",
    "    return default_logger\n",
    "\n",
    "logger = get_logger(\"douban_spider\")\n",
    "\n",
    "class Douban_corpus_spider(_Sql_Base):\n",
    "\n",
    "    def __init__(self, is_proxy = False):\n",
    "\n",
    "        self.GROUP_DICT = GROUP_DICT\n",
    "        self.MAX_PAGE = MAX_PAGE\n",
    "        self.sql_engine = self.create_engine(SQL_DICT)\n",
    "        self.is_proxy = is_proxy\n",
    "        if is_proxy:\n",
    "            self.proxyIP = self.get_proxy()\n",
    "            \n",
    "    def request_douban(self, url):\n",
    "       # 从代理池中随机取出一个IP\n",
    "        headers = {\n",
    "            'User-Agent': HEADERS\n",
    "        }\n",
    "        for i in range(MAX_GET_RETRY):\n",
    "            try:\n",
    "                if self.is_proxy:\n",
    "                    proxyIP = self.proxyIP\n",
    "                    proxies = {\n",
    "                        'http' : proxyIP,\n",
    "                        'https': proxyIP\n",
    "                    }\n",
    "                    response = requests.get(url, proxies=proxies, headers=headers)\n",
    "                else:\n",
    "                    response = requests.get(url, headers=headers)\n",
    "                if response.status_code != 200:\n",
    "                    raise HTTPError(response.status_code, url)\n",
    "                else:\n",
    "                    print('proxy: %s成功获得数据 %s' %(self.proxyIP, url))\n",
    "                break\n",
    "            except Exception as exc:\n",
    "                logger.warn(\"%s %d failed!\\n%s\", url, i, str(exc))\n",
    "                if self.is_proxy:\n",
    "                    self.proxyIP = self.get_proxy()\n",
    "                continue\n",
    "        return response.text\n",
    "\n",
    "    def get_proxy(self):\n",
    "        try:\n",
    "            response = requests.get(PROXY_POOL_URL)\n",
    "            if response.status_code == 200:\n",
    "                print('proxy: %s' %response.text)\n",
    "                return \"http://%s\" %response.text\n",
    "        except ConnectionError:\n",
    "            return None\n",
    "\n",
    "    def spider_links(self, group, page):\n",
    "        url = '{}discussion?start={}'.format(self.GROUP_DICT[group], str(page*25))\n",
    "        html = self.request_douban(url)\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        list_ = soup.find(class_='olt').find_all('tr')\n",
    "        page_link = []; page_title = []\n",
    "        for item in list_:\n",
    "            try:\n",
    "                page_link.append(item.find('a').get('href'))\n",
    "                page_title.append(item.find('a').get('title'))\n",
    "            except:\n",
    "                continue\n",
    "        return page_link, page_title\n",
    "\n",
    "    def spider_page(self, url):\n",
    "        html = self.request_douban(url)\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        for item in soup.find(type=\"application/ld+json\"):\n",
    "            try:\n",
    "                page_author_diag = json.loads(item)['text']\n",
    "            except:\n",
    "                page_author_diag = ''\n",
    "        list_ = soup.find_all(class_='clearfix comment-item reply-item')\n",
    "        page_comments = []\n",
    "        for item in list_:\n",
    "            try:\n",
    "                page_comments.append(item.find('p').contents[0])\n",
    "            except:\n",
    "                continue\n",
    "        return page_author_diag, page_comments\n",
    "\n",
    "    def spider_group(self, group):\n",
    "        spider_outputs = {}\n",
    "        link_list = []\n",
    "        title_list = []\n",
    "        for page in range(self.MAX_PAGE):\n",
    "            link_list_page, title_list_page = self.spider_links(group, page)\n",
    "            link_list = link_list + link_list_page\n",
    "            title_list = title_list + title_list_page\n",
    "        for link in link_list:\n",
    "            spider_outputs[link] = {}\n",
    "            spider_outputs[link]['title'] = title_list[link_list.index(link)]\n",
    "            spider_outputs[link]['author_diag'], spider_outputs[link]['comments'] = self.spider_page(link)\n",
    "            self.json_write(spider_outputs, os.path.join(OUTPUT_PATH, '{}.json'.format(group)))\n",
    "        return spider_outputs\n",
    "\n",
    "    def group_dict_transfer(self, output_dict):\n",
    "        data = pd.DataFrame(output_dict).T\n",
    "        data['link'] = data.index\n",
    "        data = data.reset_index(drop = True)[['link','title','author_diag','comments']]\n",
    "        def comments_sub(a):\n",
    "            b = ''\n",
    "            for item in a:\n",
    "                b = item + '|' + b\n",
    "            return b\n",
    "        data['comments'] = data['comments'].apply(comments_sub)\n",
    "        for col in ['title','author_diag','comments']:\n",
    "            data[col] = data[col].apply(emoji.demojize)\n",
    "        return data\n",
    "\n",
    "    def run(self):\n",
    "        for group in self.GROUP_DICT.keys():\n",
    "            output_dict = self.spider_group(group)\n",
    "            output_table = self.group_dict_transfer(output_dict)\n",
    "            self.table_save(output_table, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy: 120.27.208.131:80\n",
      "proxy: http://120.27.208.131:80成功获得数据\n",
      "proxy: http://120.27.208.131:80成功获得数据\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenshinpg\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "[WARNING] 2019-05-29 17:13:39,485 - https://www.douban.com/group/topic/138418608/ 0 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B20092B70>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',)))\n",
      "[WARNING] 2019-05-29 17:13:39,485 - https://www.douban.com/group/topic/138418608/ 0 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B20092B70>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy: 109.195.227.244:8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] 2019-05-29 17:14:01,499 - https://www.douban.com/group/topic/138418608/ 1 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B20092DD8>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',)))\n",
      "[WARNING] 2019-05-29 17:14:01,499 - https://www.douban.com/group/topic/138418608/ 1 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B20092DD8>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy: 203.150.160.132:8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] 2019-05-29 17:14:23,516 - https://www.douban.com/group/topic/138418608/ 2 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B200A2EF0>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',)))\n",
      "[WARNING] 2019-05-29 17:14:23,516 - https://www.douban.com/group/topic/138418608/ 2 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B200A2EF0>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy: 163.204.245.31:9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] 2019-05-29 17:14:25,645 - https://www.douban.com/group/topic/138418608/ 3 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B200B5198>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。',)))\n",
      "[WARNING] 2019-05-29 17:14:25,645 - https://www.douban.com/group/topic/138418608/ 3 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B200B5198>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。',)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy: 47.62.123.175:8197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] 2019-05-29 17:14:27,350 - https://www.douban.com/group/topic/138418608/ 4 failed!\n",
      "('Connection aborted.', BadStatusLine('<html>\\r\\n',))\n",
      "[WARNING] 2019-05-29 17:14:27,350 - https://www.douban.com/group/topic/138418608/ 4 failed!\n",
      "('Connection aborted.', BadStatusLine('<html>\\r\\n',))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy: 203.150.160.132:8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] 2019-05-29 17:14:49,368 - https://www.douban.com/group/topic/138418608/ 5 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B200924E0>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',)))\n",
      "[WARNING] 2019-05-29 17:14:49,368 - https://www.douban.com/group/topic/138418608/ 5 failed!\n",
      "HTTPSConnectionPool(host='www.douban.com', port=443): Max retries exceeded with url: /group/topic/138418608/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000020B200924E0>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy: 177.54.97.249:3128\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n",
      "proxy: http://177.54.97.249:3128成功获得数据\n"
     ]
    }
   ],
   "source": [
    "dcs = Douban_corpus_spider(is_proxy = True)\n",
    "\n",
    "output_dict = dcs.spider_group('互相表扬夸夸小组')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
